{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJp-D51g0IDd"
      },
      "source": [
        "## **1) Importing Python Packages for GAN**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k5mFBuzzl2a"
      },
      "source": [
        "from keras.datasets import cifar10, mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# Import LeakyReLU directly from keras.layers\n",
        "from keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "!mkdir generated_images"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr-eZOzg0X79"
      },
      "source": [
        "## **2) Parameters for Neural Networks & Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RThZMDruz9cB"
      },
      "source": [
        "img_width = 32\n",
        "img_height = 32\n",
        "channels = 3\n",
        "img_shape = (img_width, img_height, channels)\n",
        "latent_dim = 100\n",
        "adam = Adam(learning_rate=0.0002)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3bcJZZg0cqy"
      },
      "source": [
        "## **3) Building Generator**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdiqZpri0iQh"
      },
      "source": [
        "def build_generator():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Create first layer, to receive the input\n",
        "    model.add(Dense(256 * 4 * 4, input_dim = latent_dim))\n",
        "    # 256 * 8 * 8; for upscaling the layers,\n",
        "    # initial shape to construct into final shape\n",
        "\n",
        "    # Create default activation function\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    # Create reshape layer\n",
        "    model.add(Reshape((4, 4,256)))\n",
        "    # 8,8,256 ; reffers to first layer\n",
        "\n",
        "    # Adding more layers for neurons and better result\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha= 0.2))\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha= 0.2))\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha= 0.2))\n",
        "    # (4,4) >> filter size\n",
        "    # strides = (2,2) >> Convolutional layers, that how NN understand images\n",
        "\n",
        "    # Create Final output layer and forming image shape\n",
        "    # the shape (3, (3,3)) reffers to image shape :\n",
        "    #    >>>  img_shape = (img_width, img_height, channels)\n",
        "    model.add(Conv2D(3, (3,3), activation= 'tanh', padding = 'same'))\n",
        "\n",
        "    #\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "generator = build_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt6QsJCW0mcI"
      },
      "source": [
        "## **4) Building Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2JzEAPv0lKt"
      },
      "source": [
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Create input layer and filter and stride layer. That makes NN understand image\n",
        "    model.add(Conv2D(64, (3,3), padding = 'same', input_shape = img_shape))\n",
        "\n",
        "    # Adding activation function\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Conv2D(128, (3,3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Conv2D(128, (3,3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Conv2D(256, (3,3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Create output layer\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbcKcKmA0q2S"
      },
      "source": [
        "## **5) Connecting Neural Networks to build GAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0Ue3TEd0xLy"
      },
      "source": [
        "GAN = Sequential()\n",
        "discriminator.trainable = False\n",
        "GAN.add(generator)\n",
        "GAN.add(discriminator)\n",
        "\n",
        "GAN.compile(loss='binary_crossentropy', optimizer=adam)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPqU8dZDaQmE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "63dbba4f-bd86-4676-8c6e-f6966993c13d"
      },
      "source": [
        "GAN.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │       \u001b[38;5;34m1,466,115\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │         \u001b[38;5;34m780,545\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,466,115</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">780,545</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,246,660\u001b[0m (8.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,246,660</span> (8.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,466,115\u001b[0m (5.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,466,115</span> (5.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m780,545\u001b[0m (2.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">780,545</span> (2.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WaNhBDwRwTG"
      },
      "source": [
        "## **6) Outputting Images**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQEJ0WbjRppy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import imageio\n",
        "import PIL\n",
        "\n",
        "save_name = 0.00000000\n",
        "\n",
        "def save_imgs(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    global save_name\n",
        "    save_name += 0.00000001\n",
        "    # print(\"%.8f\" % save_name)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    # gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    gen_imgs = (gen_imgs + 1) / 2.0\n",
        "    # gen_imgs = gen_imgs * 255\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt])\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"generated_images/%.8f.png\" % save_name)\n",
        "    plt.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE57Lk5V0xs2"
      },
      "source": [
        "## **7) Training GAN**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, batch_size = 64, save_interval = 200):\n",
        "  (X_train, _), (_, _) = cifar10.load_data()\n",
        "\n",
        "  # Rescaling the data\n",
        "  X_train = X_train / 127.5 -1.\n",
        "\n",
        "  bat_per_epo = int(X_train.shape[0] / batch_size)\n",
        "\n",
        "  # Create Y label for NN\n",
        "  valid = np.ones((batch_size,1))\n",
        "  fakes = np.zeros((batch_size, 1))\n",
        "\n",
        "  for epoch in range (epochs) :\n",
        "    for j in range(bat_per_epo) :\n",
        "      #Get Random Batch\n",
        "      idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "      imgs = X_train[idx]\n",
        "\n",
        "      # Generate Fakes Images\n",
        "      noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "      gen_imgs = generator.predict(noise)\n",
        "\n",
        "      # Train Discriminator\n",
        "      d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "      d_loss_fake = discriminator.train_on_batch(gen_imgs, fakes)\n",
        "      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "      noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "      # Inverse Y label\n",
        "      g_loss = GAN.train_on_batch(noise, valid)\n",
        "\n",
        "      print(\"******* %d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100* d_loss[1], g_loss[0]))\n",
        "    save_imgs(epoch)\n",
        "\n",
        "train(1000, batch_size = 64, save_interval = 200)"
      ],
      "metadata": {
        "id": "LJc1MkJV7OVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS9wDLeRLUOB"
      },
      "source": [
        "noise = np.random.normal(0, 1, (1,latent_dim))\n",
        "gen_imgs = generator.predict(noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rlgu8g9Lik9"
      },
      "source": [
        "gen_imgs = (gen_imgs + 1) / 2.0\n",
        "plt.imshow(gen_imgs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po-jSQoN1Azl"
      },
      "source": [
        "### **8) Making GIF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPShgQpg1EMy"
      },
      "source": [
        "# Display a single image using the epoch number\n",
        "# def display_image(epoch_no):\n",
        "#   return PIL.Image.open('generated_images/%.8f.png'.format(epoch_no))\n",
        "\n",
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('generated_images/*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "\n",
        "  if filenames:  # Check if filenames is not empty\n",
        "    image = imageio.imread(filenames[-1])\n",
        "    writer.append_data(image)"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}